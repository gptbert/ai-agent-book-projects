# Cursor Chat: ai-agent-book

## Metadata
- **Project**: ai-agent-book
- **Path**: `/Users/boj`
- **Date**: 2025-10-06 17:51:42
- **Session ID**: `17bd536f-9b99-48da-9fc4-ed160294beaa`

## Conversation

### 👤 You

模型后训练与 RAG、上下文学习的对比选型 需要加入，SFT/RL 很难准确记忆大量事实，如果需要补充关于一个领域的大量事实，需要通过 continue pretrain

---

### 👤 You

模型后训练与 RAG、上下文学习的对比选型 需要加入，SFT/RL 很难准确记忆大量事实，如果需要补充关于一个领域的大量事实，需要通过 continue pretrain，而为了避免灾难性遗忘，continue pretrain 必须有较大的数据量，并且做好数据配比（通用数据 vs 领域数据），因此成本比 SFT 高很多。因此，记忆领域事实或者用户记忆更适合用 RAG 或 ICL 方式

---

### 🤖 Cursor Assistant

我来查看当前chapter7.md的内容，然后在合适的位置加入这部分对比选型的内容。

---

### 🤖 Cursor Assistant

我看到chapter7.md已经有"模型后训练与 RAG、上下文学习的对比选型"这一节（第69-86行）。我会在这一节中合适的位置加入关于事实记忆和continue pretrain的论述，使内容更完整。

---

### 🤖 Cursor Assistant

完成！我已经将关于模型后训练与 RAG、上下文学习对比选型的内容加入到 chapter7.md 的第77行。

主要添加的内容包括：

1. **SFT/RL 的局限性**：很难准确记忆大量事实性知识
2. **Continue Pretrain 的必要性**：如果确实需要让模型掌握某个领域的大量事实，必须采用持续预训练
3. **成本考量**：为了避免灾难性遗忘，持续预训练必须准备较大的数据量，并且精心设计数据配比（通用数据 vs 领域数据），因此成本远高于 SFT
4. **实践建议**：记忆领域事实或用户记忆这类任务更适合采用 RAG 或 ICL 方式，而非通过后训练将知识硬编码到参数中

这段内容自然地融入到了后训练（SFT/RL）价值的描述中，与整节的其他内容形成了完整的对比分析框架。

---


*Exported from [Cursor View](https://github.com/saharmor/cursor-view)*